\chapter{Background and Technologies}
\label{chap:background}

This chapter provides the necessary technical background to understand the system design and implementation presented in subsequent chapters. We cover Kubernetes fundamentals, the operator pattern, Custom Resource Definitions, and the REAR protocol.

\section{Kubernetes Architecture}
\label{sec:kubernetes-arch}

Kubernetes is an open-source container orchestration platform originally developed by Google and now maintained by the Cloud Native Computing Foundation (CNCF)~\cite{TODO:kubernetes-paper}. It automates deployment, scaling, and management of containerized applications.

\subsection{Core Components}

A Kubernetes cluster consists of two types of nodes:

\paragraph{Control Plane Components} run on master nodes:
\begin{itemize}
    \item \textbf{kube-apiserver}: Exposes the Kubernetes API, serving as the frontend for the control plane
    \item \textbf{etcd}: Distributed key-value store for cluster state
    \item \textbf{kube-scheduler}: Assigns pods to nodes based on resource requirements
    \item \textbf{kube-controller-manager}: Runs controller processes for nodes, replication, endpoints, etc.
    \item \textbf{cloud-controller-manager}: Interacts with cloud provider APIs
\end{itemize}

\paragraph{Node Components} run on worker nodes:
\begin{itemize}
    \item \textbf{kubelet}: Agent ensuring containers run in pods
    \item \textbf{kube-proxy}: Network proxy implementing Kubernetes Services
    \item \textbf{Container runtime}: Software for running containers (Docker, containerd, CRI-O)
\end{itemize}

% TODO: Add architecture diagram
\begin{figure}[ht]
    \centering
    % TODO: Create and include figure
    % \includegraphics[width=0.9\textwidth]{figures/kubernetes-architecture.pdf}
    \caption{Kubernetes architecture showing control plane and worker nodes}
    \label{fig:k8s-arch}
\end{figure}

\subsection{Kubernetes API and Objects}

Kubernetes uses a declarative API where users specify the desired state of resources through YAML or JSON manifests. The system continuously works to achieve and maintain this desired state.

Key resource types include:
\begin{itemize}
    \item \textbf{Pod}: Smallest deployable unit, encapsulating one or more containers
    \item \textbf{Deployment}: Manages stateless applications with replica sets
    \item \textbf{Service}: Exposes pods over the network
    \item \textbf{Namespace}: Logical cluster partitioning
    \item \textbf{ConfigMap/Secret}: Configuration and sensitive data
    \item \textbf{PersistentVolume/PersistentVolumeClaim}: Storage abstraction
\end{itemize}

\subsection{Resource Model}

Kubernetes tracks compute resources for each node:

\begin{itemize}
    \item \textbf{Capacity}: Total resources on a node
    \item \textbf{Allocatable}: Resources available for pods (Capacity minus system reservations)
    \item \textbf{Requests}: Resources guaranteed to containers
    \item \textbf{Limits}: Maximum resources a container can use
\end{itemize}

The scheduler uses resource requests to make placement decisions, ensuring nodes have sufficient capacity.

\section{Kubernetes Operators}
\label{sec:operators}

\subsection{Operator Pattern}

The Operator pattern extends Kubernetes with application-specific knowledge~\cite{TODO:operator-pattern}. An operator is a custom controller that watches Kubernetes resources and takes actions to reconcile actual state with desired state.

Operators enable:
\begin{itemize}
    \item Automating complex operational tasks
    \item Encoding domain-specific knowledge
    \item Managing full application lifecycle (install, upgrade, backup, recovery)
\end{itemize}

\subsection{Controller Pattern and Reconciliation Loop}

Controllers follow a reconciliation loop:

\begin{algorithm}
\caption{Controller Reconciliation Loop}
\label{alg:reconciliation}
\begin{algorithmic}[1]
\LOOP
    \STATE Watch for resource changes
    \STATE Get current state from cluster
    \STATE Compare with desired state
    \IF{current state $\neq$ desired state}
        \STATE Take actions to reconcile
        \STATE Update resource status
    \ENDIF
    \STATE Requeue if needed
\ENDLOOP
\end{algorithmic}
\end{algorithm}

This pattern provides:
\begin{itemize}
    \item \textbf{Level-based triggering}: Controllers react to current state, not events
    \item \textbf{Idempotence}: Reconciliation can be safely repeated
    \item \textbf{Self-healing}: Automatically corrects drift from desired state
\end{itemize}

\subsection{Kubebuilder Framework}

Kubebuilder is a framework for building Kubernetes operators using Go~\cite{TODO:kubebuilder}. It provides:

\begin{itemize}
    \item Scaffolding for operator projects
    \item Code generation for CRDs and client code
    \item Integration with controller-runtime library
    \item Testing utilities and best practices
\end{itemize}

Our Resource Agent and Resource Broker are both built using Kubebuilder.

\section{Custom Resource Definitions (CRDs)}
\label{sec:crds}

\subsection{Extending Kubernetes API}

CRDs allow defining new resource types without modifying Kubernetes core code~\cite{TODO:crd-docs}. They enable:

\begin{itemize}
    \item Domain-specific resources (e.g., Advertisement, Reservation)
    \item Schema validation via OpenAPI v3
    \item Versioning and conversion between API versions
    \item Status subresources for spec/status separation
    \item Printer columns for kubectl output customization
\end{itemize}

\subsection{CRD Structure}

A CRD consists of:

\begin{lstlisting}[language=yaml, caption={CRD structure example}, label={lst:crd-structure}]
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  name: advertisements.rear.fluidos.eu
spec:
  group: rear.fluidos.eu
  versions:
  - name: v1alpha1
    served: true
    storage: true
    schema:
      openAPIV3Schema:
        # Schema definition
  scope: Namespaced
  names:
    plural: advertisements
    singular: advertisement
    kind: Advertisement
\end{lstlisting}

\subsection{Spec vs Status Convention}

Kubernetes follows a convention of separating resources into:

\begin{itemize}
    \item \textbf{Spec}: Desired state, managed by users/clients
    \item \textbf{Status}: Observed state, managed by controllers
\end{itemize}

This separation enables:
\begin{itemize}
    \item Clear ownership boundaries
    \item Optimistic concurrency control via resourceVersion
    \item Status subresource for fine-grained RBAC
\end{itemize}

Our implementations strictly follow this pattern: Resource Agents set spec fields, controllers update status fields.

\section{Controller-Runtime Library}
\label{sec:controller-runtime}

The controller-runtime library provides building blocks for Kubernetes controllers~\cite{TODO:controller-runtime}.

\subsection{Manager}

The Manager orchestrates controller execution:
\begin{itemize}
    \item Starts and stops controllers
    \item Provides shared clients and caches
    \item Handles leader election for high availability
    \item Manages webhooks and health checks
\end{itemize}

\subsection{Client and Cache}

controller-runtime provides a client that:
\begin{itemize}
    \item Abstracts Kubernetes API interactions
    \item Implements caching to reduce API server load
    \item Supports typed and untyped (dynamic) access
    \item Handles retries and rate limiting
\end{itemize}

\subsection{Watches and Event Handlers}

Controllers register watches for resource types:

\begin{lstlisting}[language=Go, caption={Watch registration example}, label={lst:watch}]
err := ctrl.NewControllerManagedBy(mgr).
    For(&rearv1alpha1.Advertisement{}).
    Watches(
        &corev1.Pod{},
        handler.EnqueueRequestsFromMapFunc(r.findAdvertisementsForPod),
    ).
    Complete(r)
\end{lstlisting}

Watches can be:
\begin{itemize}
    \item \textbf{Primary}: For the main resource type (e.g., Advertisement)
    \item \textbf{Secondary}: For related resources (e.g., Pods affecting Advertisements)
\end{itemize}

Event handlers map watched resources to reconciliation requests.

\subsection{Predicates}

Predicates filter events before reconciliation:

\begin{lstlisting}[language=Go, caption={Predicate example}, label={lst:predicate}]
predicate.Funcs{
    UpdateFunc: func(e event.UpdateEvent) bool {
        // Only reconcile if resource changed meaningfully
        return e.ObjectOld.GetGeneration() != e.ObjectNew.GetGeneration()
    },
}
\end{lstlisting}

This prevents unnecessary reconciliations from status-only updates.

\section{REAR Protocol}
\label{sec:rear-protocol}

\subsection{Protocol Overview}

The Resource Exchange and Advertisement for the Continuum (REAR) protocol defines mechanisms for resource management in federated cloud-edge environments~\cite{TODO:rear-protocol}.

REAR consists of three main phases:

\begin{enumerate}
    \item \textbf{Advertisement}: Resource providers publish available resources
    \item \textbf{Discovery}: Consumers discover available resources matching requirements
    \item \textbf{Reservation}: Consumers reserve resources atomically
\end{enumerate}

% TODO: Add REAR protocol diagram
\begin{figure}[ht]
    \centering
    % TODO: Create figure
    % \includegraphics[width=0.9\textwidth]{figures/rear-protocol.pdf}
    \caption{REAR protocol phases: Advertisement, Discovery, and Reservation}
    \label{fig:rear-protocol}
\end{figure}

\subsection{Advertisement Phase}

Resource providers (clusters) advertise their capabilities:

\begin{itemize}
    \item Available CPU and memory
    \item Cost information (per-unit pricing)
    \item Geographic location
    \item Network characteristics
    \item Specialized hardware (GPUs, FPGAs)
\end{itemize}

Advertisements are periodically refreshed to reflect current availability.

\subsection{Discovery Phase}

Resource consumers query for clusters matching requirements:

\begin{itemize}
    \item Minimum resource thresholds
    \item Maximum acceptable cost
    \item Locality preferences
    \item Compliance requirements
\end{itemize}

The broker returns ranked candidates based on scoring criteria.

\subsection{Reservation Phase}

Selected resources are reserved atomically:

\begin{itemize}
    \item Check-and-set operation to prevent race conditions
    \item Resource accounting updates (decrement available, increment reserved)
    \item Timeout mechanisms for unclaimed reservations
    \item Rollback on failure
\end{itemize}

\section{Optimistic Concurrency Control}
\label{sec:optimistic-concurrency}

\subsection{ResourceVersion Mechanism}

Kubernetes implements optimistic locking using resourceVersion:

\begin{itemize}
    \item Every resource has a resourceVersion (monotonically increasing)
    \item Updates must specify the current resourceVersion
    \item Conflicting updates fail with 409 Conflict
    \item Clients must refetch, re-apply changes, and retry
\end{itemize}

This enables:
\begin{itemize}
    \item High concurrency without locks
    \item Automatic conflict detection
    \item Serializability of updates via etcd
\end{itemize}

\subsection{Retry Strategies}

Failed updates should be retried with exponential backoff:

\begin{algorithm}
\caption{Exponential Backoff Retry}
\label{alg:backoff}
\begin{algorithmic}[1]
\STATE maxRetries $\gets$ 5
\STATE baseDuration $\gets$ 100ms
\STATE factor $\gets$ 2.0
\FOR{attempt $\gets$ 0 to maxRetries}
    \STATE result $\gets$ attemptOperation()
    \IF{result = success}
        \RETURN success
    \ELSIF{result = conflict}
        \STATE duration $\gets$ baseDuration $\times$ factor$^{attempt}$
        \STATE sleep(duration)
        \STATE continue
    \ELSE
        \RETURN failure
    \ENDIF
\ENDFOR
\RETURN failure
\end{algorithmic}
\end{algorithm}

\section{Go Programming Language}
\label{sec:golang}

Both our operators are implemented in Go, chosen for:

\begin{itemize}
    \item Strong ecosystem for Kubernetes development
    \item Excellent concurrency primitives (goroutines, channels)
    \item Static typing with good error handling
    \item Fast compilation and execution
    \item Native support in Kubebuilder and controller-runtime
\end{itemize}

% TODO: Mention specific Go features you used (context, interfaces, etc.)

\section{Testing Frameworks}
\label{sec:testing-frameworks}

\subsection{Ginkgo and Gomega}

We use Ginkgo (BDD testing framework) and Gomega (matcher library) for testing~\cite{TODO:ginkgo}:

\begin{lstlisting}[language=Go, caption={Ginkgo test example}, label={lst:ginkgo}]
Describe("Resource Calculator", func() {
    Context("CanReserve", func() {
        It("should return true when enough resources", func() {
            cluster := createCluster("10", "20Gi")
            result := CanReserve(cluster, "2", "4Gi")
            Expect(result).To(BeTrue())
        })
    })
})
\end{lstlisting}

\subsection{EnvTest}

EnvTest provides a real Kubernetes API server for integration testing:
\begin{itemize}
    \item Starts etcd and kube-apiserver in-process
    \item Enables testing CRDs and controllers
    \item No need for full cluster or mocking
\end{itemize}

\section{Summary}
\label{sec:background-summary}

This chapter provided essential background on:
\begin{itemize}
    \item Kubernetes architecture and resource model
    \item Operator pattern and reconciliation loops
    \item Custom Resource Definitions for API extension
    \item Controller-runtime library primitives
    \item REAR protocol for resource brokerage
    \item Optimistic concurrency control mechanisms
\end{itemize}

These concepts form the foundation for understanding the system design and implementation in the following chapters.

% TODO: Add all references to references.bib
